---
title: "Simulation von Zufallszahlen"
subtitle: "Vorlesung: Computerintensive Methoden SS 2017"
author: 
- "Bernhard Preisler (734631)"
- "[Hendrik Pfaff](http://hendrik-pfaff.de) (725837)"
date: "04.05.2017"
tags: [Vorlesung, Computational Statistics, Zufallszahlen, Zufallsvariablen, Simulation]
output:
  pdf_document:
    toc: true
    toc_depth: 3
---

\newpage
# Motiviation
Zufallszahlen spielen eine wichtige Rolle in Wissenschaft, Technik und Industrie. Sie werden beispielsweise in der Kryptographie bei der Wahl eines Schlüssels, bei Computersimulationen zur Erzeugung von unvorhergesehenen Ereignissen oder in der statistischen Analyse bei der Auswahl von Stichproben benutzt.  
Die Erzeugung von Zufälligkeiten in einem Computer (ein deterministischer Automat) stellt allerdings eine besondere Herausforderung dar, da jede Operation durch die Vorherige definiert wird und daher (theoretisch) berechenbar ist.

# Definitionen
Um möglichen Verwirrungen vorzubeugen, werden in diesen Kapitel Begrifflichkeiten in Bezug aus das Thema Simulation von Zufallszahlen eingeführt und abgegrenzt.

## Simulation
In einigen Situationen besteht die Notwendigkeit etwas zu simulieren, zum Beispiel wenn ein Experiment oder ein Vorhaben zu teuer oder gefährlich wird. Generell wird versucht eine Simulation aufzubauen, wenn die Realisierung eines realen Systems nicht möglich ist. Demnach ist eine Simulation ein Experiment an einem meist stark vereinfachte Modell der Realität. Dadurch besteht die Möglichkeit der Gewinnung neuer Erkenntnisse.

Beispiele für (Hardware)Simulationen:

* Flugzeugsimulator
* Ein Windkanal simuliert die Geschwindigkeit
* Hochregallager

Diese Simulationen sind meistens nur für wenige Fälle konzipiert. In unserem Fall wird jedoch die Rechnersimulation verwendet, die durch ein reduziertes mathematisches Modell versucht eine reale Problemstellung abzubilden.

## Zufallsvariablen \& Zufallszahlen
Eine \textbf{Zufallsvariable} ist eine Variable, die die Wahrscheinlichkeit eines noch nicht durchgeführten Experiments beschreibt. Beispielsweise kann solch eine Zufallsvariable den Wurf eines fairen sechseitigen Würfels beschreiben. Die Wahrscheinlichkeit für den Ausgang eines bestimmten Ergebnisses ist in diesem Beispiel gleichverteilt. Das Ergebnis wird als \textbf{Zufallszahl} beschrieben. Mathematisch wird eine Zufallsvariable mit einem Großbuchstaben $X$, $Y$, $Z$ und eine Zufallszahl mit einem Kleinbuchstaben $x$ betitelt.

## Gleichverteilung
Ein großer Teil der Zufallsgeneratoren sind gleichverteilt. In diesem Beitrag wird die \textbf{Gleichverteilung} $U(0,1)$ mit dem Intervall $(0,1)$ behandelt. Die Folge von Zufallsvariablen $(x_m)_{m\ge1}$ sind iid. Der Begriff \textbf{Iid} ist die Abkürzung für die unabhängig und identisch verteilte Folge von Zufallsvariablen. Das bedeutet, dass die Zufallsvariablen die gleiche verteilte Folge besitzen, dennoch alle unabhängig voneinander sind.

Beispiele für Zufallsexperimente mit einer Gleichverteilung sind die folgenden:

* Ein oder mehrere Würfe mit einem fairer Würfel beinhaltet nach jedem Wurf die gleiche Wahrscheinlichkeit $P(X = x) = \dfrac{1}{6}$.
* Ein oder mehrere Würfe mit einer Münze mit $P(X = x) = \dfrac{1}{2}$

## Nichtdeterministische \& deterministische Zufallsgeneratoren
Das Ergebnis eines Algorithmus verändert sich bei gleichbleibenden Eingaben nicht. Demnach lässt sich eine komplett zufällige Funktion rein durch Software nicht realisieren. Eine Möglichkeit dieses Problem zu lösen ist es bestimmte physikalische Prinzipien miteinzubeziehen. Durch deren gegebene Zufälligkeit lassen sich Funktionen erstellen, die zu ebenso zufälligen Ergebnissen führen. Dieses Prinzip nennt sich \emph{Nichtdeterminismus} und diese Art von Generatoren werden die \textbf{nichtdeterministischen Zufallsgeneratoren} genannt.\newline

Hierzu wird oft Hardware verwendet, die durch Sensoren physikalische Effekte messen kann. Unter anderem: 

* Radioaktiver Zerfall
* Wärmerauschen
* zufällige quantenmechanische Vorgänge
* Atmosphärenrauschen (wie analoges Radio, das nicht auf einen Sender abgestimmt ist)

\begin{figure}[ht]
	\centering
  \includegraphics[width=100px, height=100px]{img/FST-01_board.png}
	\caption {Der Flying Stone Technology FST-01 erzeugt echte Zufallszahlen aus dem Rauschen bei der Analog-Digital Signalumwandlung.}
	\label{fig2}
\end{figure}

Allerdings müssen physikalische Beobachtungen in einem angemessen großen Zeitabstand zueinander erfolgen. Die Dauer der Messungen kann variieren und nur so kann ihre Unabhängigkeit gewährleistet werden. Dies führt häufig dazu, dass nichtdeterministische Generatoren für die Erzeugung der Initialwerte verwendet werden, aus welchen dann \textbf{deterministischen Zufallsgeneratoren}, also Algorithmen, weitere \textbf{Pseudozufallszahlen} generieren.

# Erzeugen von (Pseudo)Zufallszahlen

Bevor mit dem Bau eines deterministischen Zufallsgenerators begonnen wird, stellt sich die Frage, welches Ziel ein solcher Zufallsgenerator erfüllen soll. Umgangsprachlich kann ein Ziel für die Simulation von Zufallszahlen auf einen Rechner folglich definiert werden:

> \textbf{"... ein auf einem Rechner ablauffähiges Zufallsexperiment zu erhalten, ..."}, Michael Kolonk

Weiterhin besteht die Möglichkeit die Definition auf einer mathemathischen Ebene zu heben.

> Eine Folge von iid. Zufallsvariablen $(X_n)_{n\geq0}$ mit $U(0,1)$, Michael Kolonk

Alle Pseudozufallsgeneratoren kommen an einer Position an, in der sich die pseudo zufällig generierten Zahlen wiederholen. Dies wird als \textbf{Periodenlänge} bezeichnet. Ein gutes Beispiel ist der Generator $x_{n+1} := (5x_n + 1)\ MOD\ 8$. Wird $x_0 = 1$ gesetzt, werden die Zahlenfolge $1,6,7,4,5,2,3,0,1,6,7\ ...$ generiert. Die maximale Periodenlänge beträgt in diesem Beispiel 8.

## Generatoren für gleichverteilte Zufallszahlen

### Mittquadratverfahren
Das \textbf{Mittquadratverfahren (engl.: Middle-Square method)} ist einer der ältesten und vergleichsweise einfachsten Algorithmen zur Erzeugung gleichverteilter (Pseudo)Zufallszahlen. Er wurde 1946 von John von Neumann entwickelt. Bei dieser Methode wird ein beliebiger $k$-stelliger (meistens $k=8$) Initialwert $x_n \in \{0,1...,10^k-1\}$ genommen und quadriert. Die mittleren acht Zieffern dieses Quadrats bilden den neuen Seed.

So können mit der Rekursionvorschift
$$x_{n+1} := mittlere\ k\ Ziffern\ von\ x^2_n$$
immer solange Zahlen gebildet, bis das erzeugte $x_{n+1}=0$ ist. Bei diesem simplen Algorithmus ist allerdings eine Periodenzahl größer als $8^k$ bei $k$-stelligen Zahlen nicht möglich. 

Nehmen wir den Initialwert von $$x_0=12345678$$
so folgt daraus nach diesem Algorithmus

$$x_0=\underline{12345678}$$
$$x_1=12345678^2=0152\underline{41576527}9684$$
$$x_2=41576527^2=1728\underline{60759738}1729$$
$$x_3=60759738^2=...$$

Bemerkungen:

* Inzwischen ist bewiesen, dass der Algorithmus, unabhängig des Startwertes, gegen 0 konvergiert.
* Die Periodenlänge ist nicht groß.
* Frühere Verwendung als Hash-Funktion.

### Mersenne-Twister
Der Mersenne-Twister wurde 1997 von Makoto Matsumoto und Takuji Nishimura im Jahr 1997 entwickelt und ist eine Weiterentwicklung des TGFSR (Twisted The Generalized Feedback Shift Register). Der Generator gilt als quasi-Standard für moderne Pseudozufallszahlengeneratoren und wird in zahlreichen Programmiersprachen und Softwareanwendungen verwendet. Er wurde mit einer sehr langen Periodenlänge von $p = 2^{19937} - 1$ erweitert, die eine Mersenne-Primzahl ist. Weiterhin zählt der Mersenne-Twister zu den gleichverteilten Pseudozufallszahlengeneratoren.

Der \textbf{Algorithmus} startet, indem er mit einem Seed $n$ verschiedene binäre Wörter $x_1,\ ...\ , x_n$ mit jeweils $w$ Bit generiert. Die Initialwörter können von einem anderen Pseudozufallszahlengenerator stammen. Hierbei muss drauf geachtet werden, dass nicht zu viele Wörter mit 0 initialisiert werden. Zusätzlich müssen beim Start des Algorithmus mehrere Bitmasken für binäre Operationen definiert werden. Nach der Initialisierung, berechnet der Mersenne-Twister den nächsten Zustand.

Die \textbf{twist}-Funktion wird hierzu rekursiv als
$$x_{k+n}:=x_{k+m}\oplus((x_{k}^u || x_{k+1}^l)A)$$
$$k = 0,1,...$$
dargestellt. Hierbei sind $||$ als bitweises `ODER`, $\oplus$ als bitweises `XOR` dargestellt sowie $x^u$ und $x^l$ als Anwendungen der höheren und niederen Bitmasken. Die Twist Transformation A ist in der rationalen Normalform definiert.

$$A=R=\begin{pmatrix}
  0 & I_{w-1} \\
  a_{w-1} & (a_{w-2},...,a_0)
 \end{pmatrix}$$
mit $I_{w-1}$ als Identitätsmatrix. 

Sollen jetzt aus den transformierten Wörtern Zufallszahlen ausgegeben werden, werden vorher, ähnlich wie bei \textbf{Generellen rückgekoppelten Schieberegistern (engl.: Generalized Feedback Shift Register)}, hintereinander \textbf{Tempering Transformationen} durchlaufen um eine bessere Gleichverteilung zu erreichen. Das Tempering ist beim Mersenne-Twister wie folgt
$$y:=x\oplus(x >> u)$$
$$y:=y\oplus((y<<s)\wedge b)$$
$$y:=y\oplus((y<<t)\wedge c)$$
$$z:=y\oplus(y>>l)$$
definiert.

So lässt sich der Algorithmus in sechs Schritte aufgliedern:

1. Parameter und Bitmasken definieren
2. Initialisieren von $n$ Wörtern per Seed
3. Logische Verknüpfung der höheren Bits $y$ von $x_i$ mit den niederen Bits von $x_{i+1}
4. $y$ mit Matrix $A$ multiplizieren
5. Tempering
6. Zähler $i$ um $1$ erhöhen

Bemerkungen:

* Durch die Bitoperationen ist der Algorithmus sehr schnell.
* Die Parallelisierung ist leicht zu realisieren.
* Der Generator benötigt ca. 2,5 kByte, welches auf kleineren Systemen mit wenig Cache zu Performanceeinbußen kommt.
* Der Mersenne-Twister wird in R als Standardpseudozufallszahlengenerator benutzt.
* Das Verfahren ist nicht für kryptographische-Verfahren geeignet, keine Einwegfunktionen verwendet werden.


### Sonstige Methoden
Weitere Methoden zur Erzeugung gleichverteilter Zufallszahlen sind unter anderem:

* \textbf{Kongruenzgeneratoren(engl.: congruential generators)}: Mit die am weitest verbreitesten Arten von Generatoren. Sie arbeiten, mit der Summe ihrer vorherigen Zustände und dem Modulo-Operator.
* \textbf{Schieberegister-Generatoren (engl.: Linear-feedback shift register)}: Basierend auf logischen Schaltwerken und Operationen, erzeugt dieser Generator sehr effizient Sequenzen von Pseudozufallszahlen.
* \textbf{Tausworthe-Generatoren (engl.:Tausworthe generators)}: Erzeugt bitweise Zufallszahlen.

## Generatoren für sonstige Verteilungen

### Inversionsmethode
Mit Hilfe der \textbf{Inversionsmethode (engl.: Inverse transform sampling)} lassen sich Zufallszahlen (fast) beliebiger diskreter und stetiger Wahrscheinlichkeitsverteilungen erzeugen. Diesem Generator liegt das Prinzip zugrunde, dass sich aus gleichverteilten Zufallsvariablen auch welche anderer Verteilungen generieren lassen (\textbf{Inversionsprinzip}).

Es sei $F$ eine Verteilungsfunktion und $U$ eine $U(0,1)$-verteilte Zufallsvariable. Dann gilt: Die allgemeine Inverse $Y:=F^{-1}(U)$ hat die Verteilungsfunktion $F$ d.h. $$P(Y \leq t)=F(t), t\in \mathbb{R}$$

Das Vorgehen um aus einer gleichverteilten Zufallszahl eine mit bestimmter Verteilung zu machen ist nun:

1. Erzeuge einer gleichverteilte Zufallszahl
2. Berechne den Wert der $F^{-1}$ durch Einsetzen der Zahl
3. Nehme den Wert als $F$-verteilte Zufallszahl

Oder als methode mit $F^{-1}(r)$ als `FhochMinusEins(r)` :
```{}
double FRandGen() {
  return FhochMinusEins(RandGen());
}
```
Auch wenn sich so theoretisch alle Verteilungen simulieren lassen, scheitert diese Methode in der Praxis daran, dass sich deren Quantilfunktion (z.B. bei Normalverteilung) nicht effizient berechnen lässt.

\emph{Beispiel:} Simulation der Exponentialverteilung $exp(\lambda)$

Die Exponentialverteilung ist mit der Verteilungsfunktion $$F(t)=1-e^{-\lambda t}$$ mit $t\geq0$ definiert.
Bilden wir nun die Umkehrfunktion, erhalten wir $$x=F^{-1}(y)=-\frac{1}{\lambda}ln(1-y)$$. 

```{r, warning=FALSE, echo=FALSE}
library(invgamma)
library(ggplot2)

x <- seq(0, 20, length.out=1000)
dat <- data.frame(x=x, px=dexp(x, rate=0.65))
dat2 <- data.frame(x=x, px=pinvexp(x, rate=0.65))

ggplot(data=dat2, aes(x=dat2$x, y=dat2$px, color="red")) + 
  geom_line() +
  labs(title="F^-1", x="x", y="y")
```


### Sonstige Methoden
Neben der Inversionsmethoden, gibt es noch eine ganze Reihe weitere Arten von Generatoren für speziell verteilte Zufallszahlen.

* \textbf{Verwerfungsmethode (engl.: Rejection sampling)}: Alternative zur Inversionsmethode, für Wahrscheinlichkeitsverteilungen, die zu komplex zu berechnen sind.

* \textbf{Kompositionsmethode}: Ein Verfahren, das eine zusammengesetzte Mischung aus verschiedenen Verteilungen simuliert.

# Güte eines Zufallszahlengenerators 
Doch wie gut performen die im vorigen Kapitel vorgestellten Pseudzufallsgeneratoren wirklich? In diesem Kapitel werden unterschiedliche Gütekriterien (Qualität) der Zufallsgeneratoren vorgestellt. Michael Kolonk unterteilt in seinem Buch dieses große Gebiet in die zwei Kriterien das \textbf{analytische Gütekriterium} und das \textbf{statistische Gütekriterium}.

## Analytische Gütekriterien
Im Gegensatz zu dem statistischen Gütekriterium macht das \textbf{analytische Gütekriterium} über spezielle Zufallzahlengeneratoren starke Aussagen über die Güte. Jedoch bringt dies das Problem mit sich, dass diese Aussagen nur über diesen speziellen Generator gelten und daher für den Vergleich mit weiteren Generatoren nicht ideal ist. In diesem Fall wird versucht die Güte anhand eines Modells im Vergleich zum Zufallsexperiment anzunähern und mit vergleichbaren Eigenschaften wird versucht die Güte zu überprüfen. Das Modell sieht wie folgt aus.

$$ (X_n)_{n\ge0} \sim U(0,1)iid$$
<!-- TODO nochmal erklären was das Modell bedeutet -->

Dabei unterscheiden sich die Untersuchungen in die zwei grundsätzlichen Gebiete empirisch und analytisch. Die \textbf{empirische Untersuchung} nimmt ein bestehendes mathematisches Modell an und überprüft, ob die beobachteten Ereignisse von Zufallszahlen mit dem mathematischen Modell zusammenpasst. Dabei besteht die Möglichkeit diese Untersuchung graphisch oder statistisch durchzuführen. Folgende Einschränkungen muss die die empirische Untersuchung hinnehmen.

* Es besteht nur die Möglichkeit endlich viele Bedingungen zu überprüfen 
* Die obere Foderung ist zu stark und kann nur approximiert werden
<!-- Hier gibt es noch eine weitere Einschränkung TODO -->

Die \textbf{analytische Untersuchung} versucht die Güte des Zufallsgenerators anhand mathematischer-analystischer Methoden nachzuweisen.

### d-gleichverteilte Folgen
Um zu prüfen, ob ein Generator gleichverteilte Zufallszahlen generiert, besteht die Möglichkeit mit d-gleichverteile Folgen zu arbeiten. Es können nur eine endliche Zufallszahlenfolge $(x_n)_{n \ge 0}$ mit einer Länge $d$ überprüft werden. Sollte die Beobachtung wiederholt werden und unabhängig sein, sollten die Teilstücke disjunkt gewählt werden. Weiterhin existiert die Möglichkeit, dass die Zahlenfolgen sich schneiden können. $\tilde{x}_i$ ist für in der Form

$$\tilde{x}_i := (x_{ik}, x_{ik+1},...,x_{ik+d-1}),\quad i = 0,1,...$$
überlappend. Der Parameter $k$ bezeichnet die Position des Tupels und $d$ die Größe des Tupels. Dabei gelten folgende Eigenschaften. 

$$f_i(k,d)=\begin{cases}\tilde{x_i} \text{ überlappend}&\text{, wenn }1 \le k \le d - 1\\
                       \tilde{x_i} \text{ disjunkt und lückenlos}&\text{, wenn }k = d\\
                       \tilde{x_i}\text{ disjunkt und gespreizt}&\text{, wenn }k > d\end{cases}$$

Das folgende \textbf{1. Beispiel} arbeitet mit $k = d = 2$, also disjunkte und lückenlose, Folgen.

$$\tilde{x}_0 := (x_{0*2}, x_{0*2+1}) = (x_{0}, x_{1})$$
$$\tilde{x}_1 := (x_{1*2}, x_{1*2+1}) = (x_{2}, x_{3})$$
$$\vdots$$
Mit $i = 1, 2 ...$, wobei $i$ der i-te Datensatz ist.

Das \textbf{2. Beispiel} arbeitet mit $k = 3$ und $d = 2$. Dabei ist zu beachten, dass die 2-Tupel mit $k > d$ disjunkt und gespreizt sind.

$$\tilde{x}_0 := (x_{0*3}, x_{0*3+1}) = (x_{0}, x_{1})$$
$$\tilde{x}_1 := (x_{1*3}, x_{1*3+1}) = (x_{3}, x_{4})$$
$$\vdots$$
Mit $i = 1, 2 ...$, wobei $i$ der i-te Datensatz ist. In diesem Beispiel fällt auf, dass $x_2$ in keinem 2-Tupel verkommen wird. Demnach sind die 2-Tupel gespreizt.

Das \textbf{3. Beispiel} arbeitet mit $k = 2$ und $d = 3$. Ausgehend von den definierten Eigenschaften müssten mit den Parametern überlappende 3-Tupel auftreten, da $1 \le k \le d - 1$ gilt. 

$$\tilde{x}_0 := (x_{0*2}, x_{0*2+1}, x_{0*2+2}) = (x_{0}, x_{1}, x_{2})$$
$$\tilde{x}_1 := (x_{1*2}, x_{1*2+1}, x_{1*2+2}) = (x_{2}, x_{3}, x_{4})$$
$$\vdots$$
Wie vermutet sind die 3-Tupel überlappend. Im Beispiel existiert $x_2$ in $\tilde{x}_0$ und $\tilde{x}_1$, demnach sind die 3-Tupel überlappend.

Im folgenden Kapitel werden die Tupel benutzt, um die Daten zu visualisieren. Dabei gilt immer $k = d$, also disjunkt und lückenlos.




### Graphische Überprüfung der Gleichverteilung
Jetzt gilt die vorgeschlagenen Bedingungen anhand von graphischen Mitteln zu untersuchen. Als Beispiel wurde der Mersenne-Twister, Super-Duper und PP-Coincidence ausgewählt. Alle ausgewählten Verfahren sollten nach Möglichkeit gleichverteilt nach der Verteilung $U(0,1)$ erfüllen. 

Der \textbf{Mersenne-Twister} arbeitet mit einer Periodenlänge von $p = 2^{19937} - 1$. Wie der Name schon sagt, ist das eine Mersenne-Prinzahl. Der Pseudozufallszahlengenerator \textbf{Super-Duper} wurde in den 70ger Jahren erfunden und arbeitet mit einer Periodenlänge von $p = 6*10^{18}$.

Unterteilt werden die Zufallszahlenergebnisse jedes Verfahren in $2^5$ gleich große Teilintervalle $I_0,...,I_{31}$. Durch die Unterteilung besteht die Möglichkeit die Anzahl der Vorkommnisse in jedem Teilintervall mit der Formel
$$h_i := \displaystyle\sum_{n=0}^{N-1} 1_{I_i}(u_n)$$
zu berechnen. Die relativen Häufigkeiten können für jedes Intervall mit $\dfrac{h_i}{N}$ bestimmt werden.

```{r, warning=FALSE, error=FALSE, echo=FALSE}
# Berechnet die neue Zufallszahl
PP.Coincidence.CalculateNumber <- function (randomNumber) {
  first <- as.numeric(substr(randomNumber, 0, 5))
  second <- as.numeric(substr(randomNumber, 6, 10))
  
  # Ist der zweite Teil 0 oder nicht definiert =>
  # Mache ein XOR mit den hinteren Stellen von der aktuellen Zeit
  if(is.na(second) || second == 0) {
    second <- bitwXor(first, as.numeric(substr(as.numeric(Sys.time()), 6, 10)))
  }
  # Die eigentliche Berechnung
  return (first * second)
}

# Initialaufruf mit einer Anzahl von Zufallszahlen
PP.Coincidence <- function(numberOfRandomNumbers){
  rngNumber <- as.numeric(Sys.time())
  randomNumberList <- c()
  
  for(i in 1:numberOfRandomNumbers){
    rngNumber <- PP.Coincidence.CalculateNumber(rngNumber)
    randomNumberList <- c(randomNumberList, rngNumber/10000000000)
  }
  randomNumberList
}
```
```{r, warning=FALSE, error=FALSE, echo=FALSE}
library(ggplot2)
numberOfRandomNumbers <- 10000

RNGkind("Mersenne-Twister") # matches  "Mersenne-Twister"
datamt = data.frame(data = runif(numberOfRandomNumbers), KindOfRandom = "Mersenne-Twister", pos = 1:numberOfRandomNumbers)

RNGkind("Super") # matches  "Super-Duper"
datasd = data.frame(data = runif(numberOfRandomNumbers), KindOfRandom = "Super-Duper", pos = 1:numberOfRandomNumbers)

RNGkind("Wichmann-Hill") # matches  "Wichmann-Hill"
datawh = data.frame(data = PP.Coincidence(numberOfRandomNumbers), KindOfRandom = "PP-Coincidence", pos = 1:numberOfRandomNumbers)

data <- rbind(datamt, datasd, datawh)

ggplot(data, aes(x = data, color = KindOfRandom, fill = KindOfRandom)) + 
  geom_histogram(bins = 32) + 
  facet_grid(~ KindOfRandom) +
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Unterschiedliche Zufallszahlengeneratoren pro Histogramm (Verteilung)",
  x = "Generierte 10000 Zufallszahlen (32er Bins)",
  y = "Anzahl der Zufallszahlen pro Bin") +
  theme(plot.title = element_text(hjust = 0.5))
```

Die obige Abbildung visualisiert die drei genannten Pseudozufallszahlengeneratoren mit einer Anzahl von jeweils $N = 10000$ Zahlen pro Generator in einem Histogramm. Die Zahlen wurden in 32er Bins eingeteilt mit $i = \{1, ..., 32\}$. Da alle drei Generatoren $U(0,1)$ sind, müsste die Anzahl der Zufallszahlen pro bin mit $\dfrac{N}{max(i)} = 312,5$ annährend berechnen lassen. Wird dazu die obige Abbildung gegengestellt, kann subjektiv erkannt werden, dass sich bis auf die äußeren Bins alle weiteren sich in dem errechneten Bereich bewegen. 

Allerdings birgt die Prüfung auf Gleichverteilung durch dieser Art der Visualisierung einer Gefahr. Denn der Generator $x_{n+1} = (x_n + 1)\ MOD\ M$ erzeugt eine ideale Gleichverteilung.

```{r, warning=FALSE, error=FALSE, echo=FALSE}
ggplot(data, aes(y = data, x = pos, color = KindOfRandom)) + 
  geom_point(size = 0.01) +
  facet_grid(~ KindOfRandom) +
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Zufallszahlengeneratoren mit d = 1",
  x = "Zufallszahlen",
  y = "Spannweite des Zufallsgenerators") +
  theme(plot.title = element_text(hjust = 0.5))
```

Die obige Abbildung veranschaulicht einen Plot mit einer "d-gleichverteilt" ($d=1$) von den drei behandelten Pseudozufallsgeneratoren. Zwischen $n$ (x-Achse) und $x_n$ (y-Achse) sollte es keinerlei Zusammenhang geben, da die generierte Zufallszahl $x_n$ möglichst unabhängig von seiner Position $n$ sein soll. Entstehen in einem derartigen Plot wiederkehrende Muster ist der Generator nicht optimal. Im gegebenen Fall entstehen keine Hinweise auf Muster, die Flächen sehen gleichmäßig aus.

Weiterhin wird geprüft, ob "d-gleichverteilt" mit $d = 2$ gilt.

```{r, warning=FALSE, error=FALSE, echo=FALSE}
datamt2 <- data.frame(dataX = datamt[seq(1, 5000, 2),]$data, 
                      dataY = datamt[seq(2, 5000, 2),]$data,
                      KindOfRandom = "Mersenne-Twister")
datasd2 <- data.frame(dataX = datasd[seq(1, 5000, 2),]$data, 
                      dataY = datasd[seq(2, 5000, 2),]$data,
                      KindOfRandom = "Super-Duper")
datawh2 <- data.frame(dataX = datawh[seq(1, 5000, 2),]$data, 
                      dataY = datawh[seq(2, 5000, 2),]$data,
                      KindOfRandom = "PP-Coincidence")

data2 <- rbind(datamt2, datasd2, datawh2)

ggplot(data2, aes(y = dataY, x = dataX, color = KindOfRandom)) + 
  geom_point(size = 0.01) +
  facet_grid(~ KindOfRandom) +
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Zufallszahlengeneratoren mit d = 2",
  x = "Zufallszahlen",
  y = "Spannweite des Zufallsgenerators") +
  theme(plot.title = element_text(hjust = 0.5))
```

### Der Spaktraltest

Ein weiteres Gütemerktmal sind die überlappenden Tupel in einem 3-dimensionalen Raum. Gerade bei Kongruenzgeneratoren können hier Ebenen entstehen, die auf einem nicht-gleichverteilten Generator hinweisen. Die untere Abbildung zeigt einen derartigen Plott mit den 3-Tupel $(u_n, u_{n+1}, u_{n+2})$ und $d = 3$ des Mersenne-Twisters. Dort ist zu sehen, dass die gegebenen Punkte den Raum gleichmäßig füllen. Das deutet auf die Gleichverteilung des Algorithmuses hin.

```{r, warning=FALSE, error=FALSE, echo=FALSE}

datamt <- data.frame(dataX = datamt[seq(1, 3333, 3),]$data, 
                       dataY = datamt[seq(2, 3333, 3),]$data, 
                       dataZ = datamt[seq(3, 3333, 3),]$data)


library(scatterplot3d)

with(datamt, {
   s3d <- scatterplot3d(dataX, dataY, dataZ, # x,y, z axis
                 main="Mersenne-Twister",
                 box=FALSE,
                 color="#F8766C",
                 pch = 16,
                 xlab="",
                 ylab="",
                 zlab="")
   
   s3d.coords <- s3d$xyz.convert(dataX, dataY, dataZ) +
  theme(plot.title = element_text(hjust = 0.5))
})
```

Die untere Abbildung zeigt die Darstellung von dem PP-Coincidence-Zufallsgenerator im Raum. Ebenfalls wurde $d = 3$ verwendet. In der Abbildung ist leicht zu sehen, dass der Algrithmus vom PP-Coincidence nicht gleichverteilt ist.

```{r, warning=FALSE, error=FALSE, echo=FALSE}

datawh <- data.frame(dataX = datawh[seq(1, 3333, 3),]$data, 
                       dataY = datawh[seq(2, 3333, 3),]$data, 
                       dataZ = datawh[seq(3, 3333, 3),]$data)


library(scatterplot3d)

with(datawh, {
   s3d <- scatterplot3d(dataX, dataY, dataZ, # x,y, z axis
                 main="PP-Coincidence",
                 box=FALSE,
                 color="#619CFF",
                 pch = 16,
                 xlab="",
                 ylab="",
                 zlab="")
   
   s3d.coords <- s3d$xyz.convert(dataX, dataY, dataZ) +
  theme(plot.title = element_text(hjust = 0.5))
})
```



## Statistische Gütekriterien

Wie in den analytischen Untersuchungen werden in der statistischen Herangehensweise die Ergebnisse der Generatoren betrachtet. Der Unterschied zu den analytischen Kriterien ist, dass die statistischen Untersuchungen auf jeden Generator und die meisten Gütekriterien anwendbar sind.

Da dieses Kapitel sich mit den statistischen Verfahren befasst, wird zu Beginn der Anpassungstest eingeführt.

### Statistische Anpassungstests

Zu Beginn muss geklärt werden, was genau ein Anpassungstests ist. Der Begriff \textbf{Anpassungstest} stammt aus der schließenden Statistik und ist dort ein Hypothesentest. Dieser Test ist eine Prüfung auf einer unbekannten Wahrscheinlichkeit einer Zufallsvariable einer bestimmten Verteilung. D. h. es existiert ein Zufallsexperiment mit einer bestimmten Wahrscheinlichkeitsverteilung, die auf ein Verteilungsmodell hinreichend genau (typische Werte: $\alpha = 0.05$, $\alpha = 0.01$) geprüft wird. 

Salopp gesagt soll eine Hypothese aufgestellt werden, die die Ergebnisse eines Zufallsexpriment $x := (x_0, ... , x_{n-1})$ einer bestimmte Verteilung (z. B. $P_0 := U(0,1)$) annähert. Um die Hypothese zu überprüfen, wird eine Prüfgröße $T(x)$ eingeführt, die den Abstand zwischen dem Verteilungsmodell $P_0$ und der Stichprobe $x$ misst. Die Prüfgröße zusammen mit dem kritischen Wert $c \in \mathbb{R}$ bilden den Test $(T,c)$. Die Herausforderung bei einem Anpassungstest ist die Wahl von der Prüfgröße und dem kritischen Wert. <!-- TODO Hier muss noch das Verhätlnis von T(x) und c beschrieben werden. Die Werte müssen berechnet werden -->

\underline{Beispiel}

Angenommen es existiert eine Stichprobe eines Zufallsgenerators $x = (u_0,...,u_{n-1}) \in [0,1]^n$ und eine Gleichverteilung $U(0,1)$. Demnach lautet die Hypothese

$$H = \{P_x = U(0,1)\}.$$

Um die Hypothese in Worten zu fassen: "Die Zufallsvariable $x$ kann durch die Gleichverteilung $U(0,1)$ beschrieben werden.". Angenommen Test $(T, c)$ mit einem Testniveau von $\alpha = 0.01$ gilt. Sollte die Situation $T(x) > c$ eintreten, wird die Hypothese abgelehnt. Dies bedeutet, dass die gegebene Stichprobe nicht zu $U(0,1)$ passt.

Wird dieser Test mit i.i.d von dem Zufallsgenerator von $x$ wiederholt, entsteht eine fehlerhafte Ablehnung des Generators von $\alpha \cdot 100 = 0.01\%$ der Fälle.

Tritt der Fall $T(x) \le c$, zeigt das lediglich, dass die gegebenen Zufallszahlen $x$ der Gleichverteilung $U(0,1)$ ähnlich sind. Das bedeutet aber nicht, dass der Zufallsgenerator $U(0,1)$ ist, da die Fehlerwahrscheinlichkeit sehr hoch ist.

## Gütetests
Weiterhin existieren noch die Gütetests, die zwecks Vollständigkeit aufgelistet werden.

* Chi-Quadrat-Test
* Kolmorgow-Test
* Serial Test
* Lücken Test

# Zufallszahlen in R
In bestimmten Situationen werden in R Zufallszahlen benötigt. R bietet dafür verschiedene Pseudzufallszahlengeneratoren, die direkt im Editor ausgewählt werden können. Dabei besteht die Möglichkeit vor dem Aufruf eines Generators (engl.: Random Number Generator) einem sogenannten \textbf{Seed} festzulegen. Ein Seed ermöglicht dem Nutzer eine Rekonstruierung der generierten Zufallszahlen nach jedem Aufruf. Wird bei einem Aufruf kein Seed gesetzt, wird einer zufällig generiert. 

Weitere Informationen können über den Hilfe-Befehl abgerufen werden.

```{r, warning=FALSE, error=FALSE}
# Ruft die Help-Page von RNG auf
?RNG
```

## Setzen eines Seeds (optional)
```{r, warning=FALSE, error=FALSE, results='hide'}
# Setzt den Seed auf 123456789 für genau den nächsten Aufruf
set.seed(123456789)

# Generiert immer die selben 10 Zufallszahlen wegen den seed.
runif(10)

# Generiert 10 Zufallszahlen ohne Seed
runif(10)
```

## Auswahl der RNG in R

R stellt die folgenden Pseudozufallsgeneratoren von Haus aus zur Verfügung.

  * Wichmann-Hill
  * Marsaglia-Multicarry
  * Super-Duper
  * Marsenne-Twister
  * Knuth-TAOCP-2002
  * Knuth-TAOCP
  * L'Ecuyer-CMRG
  * RNGkind() bietet die Möglichkeit einen eigenen Zufallszahlengenerator zu implementieren

```{r, warning=FALSE, error=FALSE,  results='hide'}
# RNGkind setzt den Pseudozufallsgenerator
# Setzt den Zufallsgenerator auf L'Ecuyer-CMRG
RNGkind("L'Ecuyer-CMRG")

# Gibt den aktuellen Zufallsgenerator aus
RNGkind()

# Setzt den Zufallsgenerator auf Mersenne-Twister (default)
RNGkind("Mersenne-Twister")
```


## Verwendung eigener RNG

Die Implementierung eigener Zufallszahlengeneratoren ist, sofern erwünscht, möglich. Für die Einbindung in der Funktion `RNGkind()` wird C-Code benötigt, der in R eingebunden wird.


### PP-Coincidence
Der PP-Coincidence wurde im Zuge eines Praktikums im Fach Computational Statistics entwickelt. Der Algorithmus lässt sich wie folgt rekursiv definieren.

$$x_{n+1}=\begin{cases}(x_n \mod{10000}) \cdot (x_n \mod{10000}) \oplus\ \text{current Time}&\text{, wenn }\vert\frac{x_n}{10000}\vert = 0\\(x_n \mod{10000}) \cdot \vert\frac{x_n}{10000}\vert &\text{, sonst}\end{cases}$$

Wobei die Betragsstriche $\vert\vert$ in diesem Fall bedeutet, dass die Nachkommastellen abgeschnitten werden. Dazu folgt der R-Code.

```{r, warning=FALSE, error=FALSE}
# Berechnet die neue Zufallszahl
PP.Coincidence.CalculateNumber <- function (randomNumber) {
  first <- as.numeric(substr(randomNumber, 0, 5))
  second <- as.numeric(substr(randomNumber, 6, 10))
  
  # Ist der zweite Teil 0 oder nicht definiert =>
  # Mache ein XOR mit den hinteren Stellen von der aktuellen Zeit
  if(is.na(second) || second == 0) {
    second <- bitwXor(first, as.numeric(substr(as.numeric(Sys.time()), 6, 10)))
  }
  # Die eigentliche Berechnung
  return (first * second)
}

# Initialaufruf mit einer Anzahl von Zufallszahlen
PP.Coincidence <- function(numberOfRandomNumbers){
  rngNumber <- as.numeric(Sys.time())
  randomNumberList <- c()
  
  for(i in 1:numberOfRandomNumbers){
    rngNumber <- PP.Coincidence.CalculateNumber(rngNumber)
    randomNumberList <- c(randomNumberList, rngNumber/10000000000)
  }
  randomNumberList
}
PP.Coincidence(5)

```
## Prüfung der Güte von Zufallszahlen
Wie im oberen Kapitel beschrieben, kann die Güte der Zufallsverteilungen in R graphisch gut dargestellt werden.

```{r, warning=FALSE, error=FALSE, results='hide'}
# Graphische Prüfung auf Gleichverteilung
ggplot(data, aes(x = data)) + 
  geom_histogram(bins = 32) + 
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Histogramm",
  x = "Generierte 10000 Zufallszahlen (32er Bins)",
  y = "Anzahl der Zufallszahlen pro Bin")

ggplot(data, aes(y = data, x = pos)) + 
  geom_point(size = 0.01) +
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Plot",
  x = "Zufallszahlen",
  y = "Spannweite des Zufallsgenerators")
```



# Quellen

[1] \textbf{J.E. Gentle, Wolfgang Härdle, James E. Gentle}, Computational Statistics

[2] \textbf{Severin Schürz} http://www.fim.uni-linz.ac.at/Lva/Web_Security/Abgaben/Schuerz-RNG.pdf

[3] \textbf{Michael Kolonk}, Stochastische Simulation

[4] \textbf{Makoto Matsumoto}, Twisted GFSR Generators, http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/ARTICLES/tgfsr3.pdf

[5] \textbf{Makoto Matsumoto}, Mersenne Twister, http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/ARTICLES/mt.pdf

[6] \textbf{D. E. Knuth}, The Art of Computer Programming, Volume 2: Seminumerical Algorithms

[7] \textbf{Zivi Gutterman, Benny Pinkas, Tzachy Reinman}, Analysis of the Linux Random Number Generator, http://www.codeplanet.eu/files/download/Analysis%20of%20the%20Linux%20Random%20Number%20Generator.pdf