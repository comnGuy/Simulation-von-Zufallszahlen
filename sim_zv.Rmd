---
title: "Simulation von Zufallszahlen"
subtitle: "Vorlesung: Computerintensive Methoden SS 2017"
author: 
- "Bernhard Preisler (734631)"
- "[Hendrik Pfaff](http://hendrik-pfaff.de) (725837)"
date: "`r format(Sys.time(), '%d.%m.%Y')`"
tags: [Vorlesung, Computational Statistics, Zufallszahlen, Zufallsvariablen, Simulation]
output:
  pdf_document:
    toc: true
---

\newpage
# Motiviation
Zufallszahlen spielen eine wichtige Rolle in Wissenschaft, Technik und Industrie. Sie werden beispielsweise in der Kryptographie bei der Wahl eines Schlüssels, bei Computersimulationen zur Erzeugung von unvorhergesehenen Ereignissen oder in der statistischen Analyse bei der Auswahl von Stichproben benutzt.  
Die Erzeugung von Zufälligkeiten in einem Computer (ein deterministischer Automat) stellt allerdings eine besondere Herausforderung dar, da jede Operation durch die Vorherige definiert wird und daher (theoretisch) berechenbar ist.

# Definitionen
Um möglichen Verwirrungen vorzubeugen, werden in diesen Kapitel Begrifflichkeiten in Bezug aus das Thema Simulation von Zufallszahlen eingeführt und abgegrenzt.

## Simulation
In einigen Situationen besteht die Notwenigkeit etwas zu simulieren, zum Beispiel wenn ein Experiment oder ein Vorhaben zu teuer oder gefährlich wird. Generell wird versucht eine Simulation aufzubauen, wenn die Realisierung eines realen Systems nicht möglich ist. Demnach ist eine Simulation ein Experiment an einem meist stark vereinfachte Modell der Realität. Dadurch besteht die Möglichkeit der Gewinnung neuer Erkenntnisse.

Beispiele für (Hardware)Simulationen:

* Flugzeugsimulator
* Ein Windkanal simuliert die Geschwindigkeit
* Hochregallager

Diese Simulationen sind meistens nur für wenige Fälle konzipiert. In unserem Fall wird jedoch die Rechnersimulation verwendet, die durch ein reduziertes mathematisches Modell versucht eine reale Problemstellung abzubilden.

<!-- Definition der Zufallsvariable mit dem Buch wiedersprüchlich??? Seite 6 TODO-->
## Zufallsvariablen \& Zufallszahlen
Eine \textbf{Zufallsvariable} ist eine Variable, die die Wahrscheinlichkeit eines noch nicht durchgeführten Experiments beschreibt. Beispielsweise kann solch eine Zufallsvariable den Wurf eines fairen sechseitigen Würfels beschreiben. Die Wahrscheinlichkeit für den Ausgang eines bestimmten Ergebnisses ist in diesem Beispiel gleichverteilt. Das Ergebnis wird als \textbf{Zufallszahl} beschrieben. Mathematisch wird eine Zufallsvariable mit einem Großbuchstaben $X$, $Y$, $Z$ und eine Zufallszahl mit einem Kleinbuchstaben $x$ betitelt.

## Gleichverteilung
Der Grund für dieses Kapitel ist, dass ein großer Teil der Zufallsgeneratoren gleichverteilt sind. In diesem Beitrag wird die \textbf{Gleichverteilung} $U(0,1)$ mit dem Intervall $(0,1)$ behandelt. Die Folge von Zufallsvariablen $(x_m)_{m\ge1}$ sind iid. Der Begriff \textbf{Iid} ist die Abkürzung für die unabhängig und identisch verteilte Folge von Zufallsvariablen. Das bedeutet, dass die Zufallsvariablen die gleiche verteilte Folge besitzen, dennoch alle unabhängig voneinander sind.

Beispiele für Zufallsexperimente mit einer Gleichverteilung sind die folgenden:

* Ein oder mehrere Würfe mit einem fairer Würfel beinhaltet nach jedem Wurf die gleiche Wahrscheinlichkeit $P(X = x) = \dfrac{1}{6}$.
* Ein oder mehrere Würfe mit einer Münze mit $P(X = x) = \dfrac{1}{2}$

## Nichtdeterministische \& deterministische Zufallsgeneratoren
Das Ergebnis eines Algorithmus verändert sich bei gleichbleibenden Eingaben nicht. Demnach lässt sich eine komplett zufällige Funktion rein durch Software nicht realisieren. Eine Möglichkeit dieses Problem zu lösen ist es bestimmte physikalische Prinzipien miteinzubeziehen. Durch deren gegebene Zufälligkeit lassen sich Funktionen erstellen, die zu ebenso zufälligen Ergebnissen führen. Dieses Prinzip nennt sich \emph{Nichtdeterminismus} und diese Art von Generatoren werden die \textbf{nichtdeterministischen Zufallsgeneratoren} genannt.\newline

Hierzu wird oft Hardware verwendet, die durch Sensoren physikalische Effekte messen kann. Unter anderem: 

* Radioaktiver Zerfall
* Wärmerauschen
* zufällige quantenmechanische Vorgänge
* Atmosphärenrauschen (wie analoges Radio, das nicht auf einen Sender abgestimmt ist)

\begin{figure}[ht]
	\centering
  \includegraphics[width=100px, height=100px]{img/FST-01_board.png}
	\caption {Der Flying Stone Technology FST-01 erzeugt echte Zufallszahlen aus dem Rauschen bei der Analog-Digital Signalumwandlung.}
	\label{fig2}
\end{figure}

Allerdings müssen physikalische Beobachtungen (um die Zahlen zu generieren) in einem angemessen großen Abstand zueinander erfolgen um Unabhängigkeit zu gewährleisten.

Demnach zeichnen sich die \textbf{deterministischen Zufallsgeneratoren} dadurch aus, dass bei gleicher Eingabe immer der selber Ausgang berechnet wird. Die so erzeugten Zahlen werden \textbf{Pseudozufallszahlen} genannt.

# Erzeugen von (Pseudo)Zufallszahlen

Bevor mit dem Bau eines deterministischen Zufallsgenerators begonnen wird, stellt sich die Frage, welches Ziel ein solcher Zufallsgenerator erfüllen soll. Umgangsprachlich kann ein Ziel für die Simulation von Zufallszahlen auf einen Rechner folglich definiert werden:

> \textbf{"... ein auf einem Rechner ablauffähiges Zufallsexperiment zu erhalten, ..."}, Michael Kolonk

Weiterhin besteht die Möglichkeit die Definition auf einer mathemathischen Ebene zu heben.

> Eine Folge von iid. Zufallsvariablen $(X_n)_{n\geq0}$ mit $U(0,1)$, Michael Kolonk

Alle Pseudozufallsgeneratoren kommen an einer Position an, inder sich die pseudo zufällig generierten Zahlen wiederholen. Dies wird als \textbf{Periodenlänge} bezeichnet. Ein gutes Beispiel ist der Generator $x_{n+1} := (5x_n + 1)\ MOD\ 8$. Wird $x_0 = 1$ gesetzt, werden die Zahlenfolge $1,6,7,4,5,2,3,0,1,6,7\ ...$ generiert. Die maximale Periodenlänge beträgt in diesem Beispiel 8.

## Generatoren für gleichverteilte Zufallszahlen

### Mittquadratverfahren
Das \textbf{Mittquadratverfahren (engl.: Middle-Square method)} ist einer der ältesten und vergleichsweise einfachsten Algorithmen zur Erzeugung gleichverteilter (Pseudo)Zufallszahlen. Er wurde 1946 von John von Neumann entwickelt. Bei dieser Methode wird ein beliebiger achtstelliger Initialwert $x_n \in \{0,1...,10^8\}$ (meistens die Uhrzeit) genommen und die Quadrate der beiden mittleren Stellen miteinander multipliziert.

Die weiteren Schritte können mit 
$$x_{n+1} := mittlere\ acht\ Ziffern\ von\ x^2_n$$
rekursiv immer weiter gebildet werden.


Bemerkungen:

* Inzwischen ist bewiesen, dass der Algorithmus, unabhängig des Startwertes, gegen 0 konvergiert.
* Der Algorithmus hat offensichtlich Probleme mit $x_n = 0$.
* Die Periodenlänge ist nicht groß.
* Verwendung als Hash-Funktion.
* Bsp. siehe: Shiny app

### Mersenne-Twister
Der Mersenne-Twister wurde 1997 von Makoto Matsumoto und Takuji Nishimura im Jahr 1997 entwickelt und ist eine Weiterentwicklung des TGFSR (Twisted The Generalized Feedback Shift Register). Er wurde mit einer sehr langen Periodenlänge von $p = 2^{19937} - 1$ erweitert, die eine Mersenne-Primzahl ist. Weiterhin zählt der Mersenne-Twister zu den gleichverteilten Pseudozufallszahlengeneratoren.

Der \textbf{Algorithmus} startet mit $N = 624$ verschiedene Wörter, die mit $Y_1\ ...\ Y_N$ bezeichnet werden. Die Initialwörter können von einem anderen Pseudozufallszahlengenerator generiert werden. Hierbei muss drauf geachtet werden, dass nicht zu viele Wörter mit 0 initialisiert werden. Sind die Initialwörter gewählt, berechnet der Mersenne-Twister die weiteren Pseudzufallszahlen wie folgt.

$$h := Y_{i-N} - Y_{i-N}\ mod\ 2^{31} + Y_{i-N+1}\ mod\ 2^{31}$$
$$Y_i := Y_{i-227}\ \oplus \lfloor h/2 \rfloor\ \oplus\ ((h mod 2)\ \cdot\ 9908B0DF_{hex})$$

Weiterhin wird durch die nächsten Formeln die Gleichverteilung sichergegestellt.

$$x := Y_i\ \oplus\ \lfloor Y_i / 2^{11}\rfloor$$
$$y := x\ \oplus\ ((x\ \cdot\ 2^7)\ \wedge\ 9D2C5680_{hex}$$
$$z := y\ \oplus\ ((y\ \cdot\ 2^15)\ \wedge\ EFC60000_{hex}$$
$$Z_i := z\ \oplus\ \lfloor z / 2^{18}\rfloor$$

$Z_i$ ist eine Zufallszahl. Dabei stellt $\oplus$ eine bitweise XOR-Operation und $\wedge$ eine bitweise UND-Operation dar.

Bemerkungen:

* Durch die Bitoperationen ist der Algorithmus sehr schnell.
* Die Parallelisierung ist leicht zu realisieren.
* Der Generator benötigt ca. 2,5 kByte, welches auf kleineren Systemen mit wenig Cache zu Performanceeinbußen kommt.
* Der Mersenne-Twister wird in R als Standardpseudozufallszahlengenerator benutzt.
* Der Mersenne-Twister ist für viele Anwendungen ein Standard-Verfahren, unteranderem ist er in R, Stata, Microsoft Excel & Mathematica implementiert.


### Sonstige
Weitere Methoden zur Erzeugung gleichverteilter Zufallszahlen sind unter anderem:

* \textbf{Kongruenzgeneratoren(engl.: congruential generators)}: Mit die am weitest verbreitesten Arten von Generatoren. Sie arbeiten, mit der Summe ihrer vorherigen Zustände und dem Modulo operator.
* \textbf{Schieberegister-Generatoren (engl.: Linear-feedback shift register)}: Basierend auf logischen Schaltwerken und Operationen, erzeugt dieser Generator sehr effizient Sequenzen von Pseudozufallszahlen.
* \textbf{Tausworthe-Generatoren (engl.:Tausworthe generators)}: Erzeugt bitweise Zufallszahlen.

## Generatoren für sonstige Verteilungen

### Inversionsmethode
Mit Hilfe der \textbf{Inversionsmethode (engl.: Inverse transform sampling)} lassen sich Zufallszahlen (fast) beliebiger diskreter und stetiger Wahrscheinlichkeitsverteilungen erzeugen. Diesem Generator liegt das Prinzip zugrunde, dass sich aus gleichverteilten Zufallsvariablen auch welche anderer Verteilungen generieren lassen (\textbf{Inversionsprinzip}).

Es sei $F$ eine Verteilungsfunktion und $U$ eine $U(0,1)$-verteilte Zufallsvariable. Dann gilt: Die allgemeine Inverse $Y:=F^{-1}(U)$ hat die Verteilungsfunktion $F$ d.h. $$P(Y \leq t)=F(t), t\in \mathbb{R}$$

Mit $F^{-1}(r)$ als Funktion `FhochMinusEins(r)` kann nun aus einer gleichverteilten Zufallszahl eine mit einer bestimmer Verteilung.
```{}
double FRandGen() {
  return FhochMinusEins(RandGen());
}
```
Auch wenn sich so theoretisch alle Verteilungen simulieren lassen, scheitert diese Methode in der Praxis daran, dass sich deren Quantilfunktion (z.B. bei Normalverteilung) nicht effizient berechnen lässt.

\emph{Beispiel:} Simulation der Exponentialverteilung $exp(\alpha)$

Die Exponentialverteilung ist mit der Verteilungsfunktion $$F(t)=1-e^{-\lambda e}$$ mit $t>0$ definiert.
Bilden wir nun die Umkehrfunktion, erhalten wir $$x=F^{-1}(y)=-\frac{1}{\lambda}ln(1-y)$$. 

```{r, echo=FALSE}
# Plot der exponentialfunktions.
library(ggplot2)
#data <- data.frame(x=seq(1:25), y=pexp(seq(1:25)))
#data2 <- data.frame(x=seq(1:25), y=seq(1:25))
#ggplot() +
#  geom_line(data=data, aes(x=data$x, y=data$y)) +
#  geom_line(data=data2, aes(x=data2$x, y=data2$y)) + 
#  labs(title="Exponentialfunktion mit Inverse")
```


Bemerkungen:

* 
* 
* 

### Sonstige Methoden
Neben den Vorgestellten Methoden, gibt es noch eine ganze Reihe weitere Generatoren für speziell verteilte Zufallszahlen.

* \textbf{Verwerfungsmethode (engl.: Rejection sampling)}: Alternative zur Inversionsmethode, für Wahrscheinlichkeitsverteilungen, die zu komplex zu berechnen sind.

* \textbf{Kompositionsmethode}: Ein Verfahren, das eine zusammengesetzte Mischung aus verschiedenen Verteilungen simuliert.

# Güte eines Zufallszahlengenerators 
Doch wie gut performen die im vorigen Kapitel vorgestellten Pseudzufallsgeneratoren wirklich? In diesem Kapitel werden unterschiedliche Gütekriterien (Qualität) der Zufallsgeneratoren vorgestellt. Michael Kolonk unterteilt in seinem Buch dieses große Gebiet in die zwei Kriterien das \textbf{analytische Gütekriterium} und das \textbf{statistische Gütekriterium}.

## Analytische Gütekriterien
Im Gegensatz zu dem statistischen Gütekriterium macht das \textbf{analytische Gütekriterium} über spezielle Zufallzahlengeneratoren starke Aussagen über die Güte. Jedoch bringt dies das Problem mit sich, dass diese Aussagen nur über diesen speziellen Generator gelten und daher für den Vergleich mit weiteren Generatoren nicht ideal ist. In diesem Fall wird versucht die Güte anhand eines Modells im Vergleich zum Zufallsexperiment anzunähern und mit vergleichbaren Eigenschaften wird versucht die Güte zu überprüfen. Das Modell sieht wie folgt aus.

$$iid (X_n)_{n\ge0} \sim U(0,1)$$
<!-- TODO nochmal erklären was das Modell bedeutet -->
Einer dieser vergleichbaren Eigenschaften ist die Überprüfung auf die Gleichverteilung sein. Dabei wird die Verteilung $X_0,...,X_{d-1}$ für alle $d \ge 1$ mit der Gleichverteilung $[0,1]^d$ verglichen und sollte bestmöglich über einstimmen. Sei $(X_n)_{n\ge0}$ eine Folge von Zufallsvariablen mit den Werten in $[0,1]$. $(X_n)_{n\ge0}$ ist i.i.d mit der Verteilung $U(0,1)$, falls für $d \in \mathbb{N}$ und alle $0 \le a_i \le b_i \le 1, i = 0,...,d-1$, gilt

$$ P(a_i < X_i \le b_i, i = 0,...,d-1) = \prod_{i=0}^{d-1}(b_i-a_i)$$
<!-- Würde die Formel rausnehmen inkl. deren Erklärung? TODO-->
Dabei unterscheiden sich die Untersuchungen in die zwei grundsätzlichen Gebiete empirisch und analytisch. Die \textbf{empirische Untersuchung} nimmt ein bestehendes mathematisches Modell an und überprüft, ob die beobachteten Ereignisse von Zufallszahlen mit dem mathematischen Modell zusammenpasst. Dabei besteht die Möglichkeit diese Untersuchung graphisch oder statistisch durchzuführen. Folgende Einschränkungen muss die die empirische Untersuchung hinnehmen.

* Es besteht nur die Möglichkeit endlich viele Bedingungen zu überprüfen 
* Die obere Foderung ist zu stark und kann nur approximiert werden
<!-- Hier gibt es noch eine weitere Einschränkung TODO -->

Die \textbf{analytische Untersuchung} versucht die Güte des Zufallsgenerators anhand mathematischer-analystischer Methoden nachzuweisen.

### d-gleichverteilte Folgen
Wie im vorigen Kapitel angesprochen, kann nur eine endliche Zahlenfolge $(x_n)_{n \ge 0}$ mit einer Länge $d$ überprüft werden kann. Sollte die Beobachtung wiederholt werden und unabhängig sein, sollten die Teilstücke disjunkt gewählt werden. 

Weiterhin existiert die Möglichkeit, dass die Zahlenfolgen sich schneiden können. $\tilde{x}_i$ ist für  in der Form

$$\tilde{x}_i := (x_{ik}, x_{ik+1},...,x_{ik+d-1}),\quad i = 0,1,...$$
überlappend. Wenn

* $1 \le k \le d - 1$ für $\tilde{x}_i$ gilt,  die Teilstücke überlappend, wenn
* $k = d$ gilt, sind die Teilstücke disjunkt und lückenlos sind, wenn
* $k > d$ gilt, sind die Teilstücke disjunkt und gespreizt sind. 

### Graphische Überprüfung der Gleichverteilung
Jetzt gilt die vorgeschlagenen Bedingungen anhand von graphischen Mitteln zu untersuchen. Als Beispiel wurde der Mersenne-Twister, Super-Duper und PP-Coincidence ausgewählt. Alle ausgewählten Verfahren sollten nach Möglichkeit gleichverteilt nach der Verteilung $U(0,1)$ erfüllen. 

Der \textbf{Mersenne-Twister} arbeitet mit einer Periodenlänge von $p = 2^{19937} - 1$. Wie der Name schon sagt, ist das eine Mersenne-Prinzahl. Der Pseudozufallszahlengenerator \textbf{Super-Duper} wurde in den 70ger Jahren erfunden und arbeitet mit einer Periodenlänge von $p = 6*10^{18}$. Als dritten Generator wurde der \textbf{Wichmann-Hill} verwendet. Er generiert Zufallszahlen mit einer Periodenlänge von mehr als $6.95 * 10^{12}$.

Unterteilt werden die Zufallszahlenergebnisse jedes Verfahren in $2^5$ gleich große Teilintervalle $I_0,...,I_{31}$. Durch die Unterteilung besteht die Möglichkeit die Anzahl der Vorkommnisse in jedem Teilintervall mit der Formel
$$h_i := \displaystyle\sum_{n=0}^{N-1} 1_{I_i}(u_n)$$
zu berechnen. Die relativen Häufigkeiten können für jedes Intervall mit $\dfrac{h_i}{N}$ bestimmt werden.

```{r, echo=FALSE}
library(ggplot2)
numberOfRandomNumbers <- 10000

RNGkind("Mersenne-Twister") # matches  "Mersenne-Twister"
datamt = data.frame(data = runif(numberOfRandomNumbers), KindOfRandom = "Mersenne-Twister", pos = 1:numberOfRandomNumbers)

RNGkind("Super") # matches  "Super-Duper"
datasd = data.frame(data = runif(numberOfRandomNumbers), KindOfRandom = "Super-Duper", pos = 1:numberOfRandomNumbers)

RNGkind("Wichmann-Hill") # matches  "Wichmann-Hill"
datawh = data.frame(data = runif(numberOfRandomNumbers), KindOfRandom = "Wichmann-Hill", pos = 1:numberOfRandomNumbers)

data <- rbind(datamt, datasd, datawh)

ggplot(data, aes(x = data, color = KindOfRandom, fill = KindOfRandom)) + 
  geom_histogram(bins = 32) + 
  facet_grid(~ KindOfRandom) +
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Unterschiedliche Zufallszahlengeneratoren pro Histogramm (Verteilung)",
  x = "Generierte 10000 Zufallszahlen (32er Bins)",
  y = "Anzahl der Zufallszahlen pro Bin")
```

Die obige Abbildung visualisiert die drei genannten Pseudozufallszahlengeneratoren mit einer Anzahl von jeweils $N = 10000$ Zahlen pro Generator in einem Histogramm. Die Zahlen wurden in 32er Bins eingeteilt mit $i = \{1, ..., 32\}$. Da alle drei Generatoren $U(0,1)$ sind, müsste die Anzahl der Zufallszahlen pro bin mit $\dfrac{N}{max(i)} = 312,5$ annährend berechnen lassen. Wird dazu die obige Abbildung gegengestellt, kann subjektiv erkannt werden, dass sich bis auf die äußeren Bins alle weiteren sich in dem errechneten Bereich bewegen. 

Allerdings birgt die Prüfung auf Gleichverteilung durch dieser Art der Visualisierung einer Gefahr. Denn der Generator $x_{n+1} = (x_n + 1)\ MOD\ M$ erzeugt eine ideale Gleichverteilung.

```{r, echo=FALSE}
ggplot(data, aes(y = data, x = pos, color = KindOfRandom)) + 
  geom_point(size = 0.01) +
  facet_grid(~ KindOfRandom) +
  theme(legend.direction = "horizontal", 
        legend.position = "bottom",
        legend.box = "horizontal") +
  labs(title = "Unterschiedliche Zufallszahlengeneratoren als Plot",
  x = "Zufallszahlen",
  y = "Spannweite des Zufallsgenerators")
```

Die obige Abbildung zeigt einen Plot von den drei behandelten Pseudozufallsgeneratoren. Zwischen $x$ und $y$ sollte es keinerlei Zusammenhang geben, da die generierte Zufallszahl $y$ möglichst unabhängig von seiner Position $x$ sein soll. Entstehen in einem derartigen Plot wiederkehrende Muster ist der Generator nicht optimal. Im gegebenen Fall entstehen keine Hinweise auf Muster, die Flächen sehen gleichmäßig aus.

### Der Spaktraltest

Ein weiteres Gütemerktmal sind die überlappenden Tupel in einem 3-dimensionalen Raum. Gerade bei Kongruenzgeneratoren können hier Ebenen entstehen, die auf einem nicht-gleichverteilten Generator hinweisen. Die untere Abbildung zeigt einen derartigen Plott mit den 3-Tupel $(u_n, u_{n+1}, u_{n+2})$ des Mersenne-Twisters. Dort ist zu sehen, dass die gegebenen Punkte den Raum gleichmäßig füllen. Das deutet auf die Gleichverteilung des Algorithmuses hin.

```{r, echo=FALSE}

datamt <- data.frame(dataX = datamt[seq(1, 3333, 3),]$data, 
                       dataY = datamt[seq(2, 3333, 3),]$data, 
                       dataZ = datamt[seq(3, 3333, 3),]$data)


library(scatterplot3d)

with(datamt, {
   s3d <- scatterplot3d(dataX, dataY, dataZ, # x,y, z axis
                 main="Mersenne-Twister",
                 box=FALSE,
                 color="#F8766C",
                 pch = 16,
                 xlab="",
                 ylab="",
                 zlab="")
   
   s3d.coords <- s3d$xyz.convert(dataX, dataY, dataZ)
})
```



## Statistische Gütekriterien

Wie in den analytischen Untersuchungen werden in der statistischen Herangehensweise die Ergebnisse der Generatoren betrachtet. Der Unterschied zu den analytischen Kriterien ist, dass die statistischen Untersuchungen auf jeden Generator und die meisten Gütekriterien anwendbar sind.

Da dieses Kapitel sich mit den statistischen Verfahren befasst, wird zu Beginn der Anpassungstest eingeführt.

### Statistische Anpassungstests

Zu Beginn muss geklärt werden, was genau ein Anpassungstests ist. Der Begriff \textbf{Anpassungstest} stammt aus der schließenden Statistik und ist dort ein Hypothesentest. Dieser Test ist eine Prüfung auf einer unbekannten Wahrscheinlichkeit einer Zufallsvariable einer bestimmten Verteilung. D. h. es existiert ein Zufallsexperiment mit einer bestimmten Wahrscheinlichkeitsverteilung, die auf ein Verteilungsmodell hinreichend genau (typische Werte: $\alpha = 0.05$, $\alpha = 0.01$) geprüft wird. 

Salopp gesagt soll eine Hypothese aufgestellt werden, die die Ergebnisse eines Zufallsexpriment $x := (x_0, ... , x_{n-1})$ einer bestimmte Verteilung (z. B. $P_0 := U(0,1)$) annähert. Um die Hypothese zu überprüfen, wird eine Prüfgröße $T(x)$ eingeführt, die den Abstand zwischen dem Verteilungsmodell $P_0$ und der Stichprobe $x$ misst. Die Prüfgröße zusammen mit dem kritischen Wert $c \in \mathbb{R}$ bilden den Test $(T,c)$. Die Herausforderung bei einem Anpassungstest ist die Wahl von der Prüfgröße und dem kritischen Wert. <!-- TODO Hier muss noch das Verhätlnis von T(x) und c beschrieben werden -->

\underline{Beispiel}

Angenommen es existiert eine Stichprobe eines Zufallsgenerators $x = (u_0,...,u_{n-1}) \in [0,1]^n$ und eine Gleichverteilung $U(0,1)$. Demnach lautet die Hypothese

$$H = \{P_x = U(0,1)\}.$$

Um die Hypothese in Worten zu fassen: "Die Zufallsvariable $x$ kann durch die Gleichverteilung $U(0,1)$ beschrieben werden.". Angenommen Test $(T, c)$ mit einem Testniveau von $\alpha = 0.01$ gilt. Sollte die Situation $T(x) > c$ eintreten, wird die Hypothese abgelehnt. Dies bedeutet, dass die gegebene Stichprobe nicht zu $U(0,1)$ passt.

Wird dieser Test mit i.i.d von dem Zufallsgenerator von $x$ wiederholt, entsteht eine fehlerhafte Ablehnung des Generators von $\alpha \cdot 100 = 0.01\%$ der Fälle.

Tritt der Fall $T(x) \le c$, zeigt das lediglich, dass die gegebenen Zufallszahlen $x$ der Gleichverteilung $U(0,1)$ ähnlich sind. Das bedeutet aber nicht, dass der Zufallsgenerator $U(0,1)$ ist, da die Fehlerwahrscheinlichkeit sehr hoch ist.


# Zufallszahlen in R
In bestimmten Situationen werden in R Zufallszahlen benötigt. R bietet dafür verschiedene Pseudzufallszahlengeneratoren, die direkt in R ausgewählt werden können. Dabei besteht die Möglichkeit vor dem Aufruf eines Generators einem sogenannten \textbf{Seed} festzulegen. Ein Seed ermöglicht dem Nutzer eine Rekonstruierung der generierten Zufallszahlen nach jedem Aufruf. Wird bei einem Aufruf kein Seed gesetzt, wird einer zufällig generiert. Weitere Informationen können über den folgenden Befehl abgerufen werden.


```{r}
# Ruft die Help-Page von RNG auf
#?RNG
```

R stellt die folgenden Pseudozufallsgeneratoren nativ zur Verfügung.

  * Wichmann-Hill
  * Marsaglia-Multicarry
  * Super-Duper
  * Marsenne-Twister
  * Knuth-TAOCP-2002
  * Knuth-TAOCP
  * L'Ecuyer-CMRG
  * RNGkind() bietet die Möglichkeit einen eigenen Zufallszahlengenerator zu implementieren

## Auswahl der RNG in R

```{r results='hide'}
# RNGkind setzt den Pseudozufallsgenerator
# Setzt den Zufallsgenerator auf L'Ecuyer-CMRG
RNGkind("L'Ecuyer-CMRG")

# Gibt den aktuellen Zufallsgenerator aus
RNGkind()

# Setzt den Zufallsgenerator auf Mersenne-Twister (default)
RNGkind("Mersenne-Twister")
```

## Setzen eines Seeds (optional)
```{r results='hide'}
# Setzt den Seed auf 123456789 für genau den nächsten Aufruf
set.seed(123456789)

# Generiert immer die selben 10 Zufallszahlen wegen den seed.
runif(10)

# Generiert 10 Zufallszahlen ohne Seed
runif(10)
```


## Eigene RNG


### PP-Coincidence
Der PP-Coincidence wurde im Zuge eines Praktikums im Fach Computational Statistics entwickelt. Der Algorithmus lässt sich wie folgt darstellen.

$$x_{n+1}=\begin{cases}(x_n \mod{10000}) \cdot (x_n \mod{10000}) \oplus\ \text{current Time}&\text{, wenn }\vert\frac{x_n}{10000}\vert = 0\\(x_n \mod{10000}) \cdot \vert\frac{x_n}{10000}\vert &\text{, sonst}\end{cases}$$

Wobei die Betragsstriche $\vert\vert$ in diesem Fall bedeutet, dass die Nachkommastellen abgeschnitten werden. Dazu folgt der R-Code.

```{r}
# Berechnet die neue Zufallszahl
PP.Coincidence.CalculateNumber <- function (randomNumber) {
  first <- as.numeric(substr(randomNumber, 0, 5))
  second <- as.numeric(substr(randomNumber, 6, 10))
  
  # Ist der zweite Teil 0 oder nicht definiert =>
  # Mache ein XOR mit den hinteren Stellen von der aktuellen Zeit
  if(is.na(second) || second == 0) {
    second <- bitwXor(first, as.numeric(substr(as.numeric(Sys.time()), 6, 10)))
  }
  # Die eigentliche Berechnung
  return (first * second)
}

# Initialaufruf mit einer Anzahl von Zufallszahlen
PP.Coincidence <- function(numberOfRandomNumbers){
  rngNumber <- as.numeric(Sys.time())
  randomNumberList <- c()
  
  for(i in 1:numberOfRandomNumbers){
    rngNumber <- PP.Coincidence.CalculateNumber(rngNumber)
    randomNumberList <- c(randomNumberList, rngNumber/10000000000)
  }
  randomNumberList
}
PP.Coincidence(5)

```
## Prüfung auf Unabhängigkeit der Zufallszahlen


# Quellen

[1] \textbf{J.E. Gentle, Wolfgang Härdle, James E. Gentle}, Computational Statistics

[2] \textbf{Severin Schürz} http://www.fim.uni-linz.ac.at/Lva/Web_Security/Abgaben/Schuerz-RNG.pdf

[3] \textbf{Michael Kolonk}, Stochastische Simulation

[4] \textbf{Makoto Matsumoto}, Twisted GFSR Generators, http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/ARTICLES/tgfsr3.pdf

[5] \textbf{Makoto Matsumoto}, Mersenne Twister, http://www.math.sci.hiroshima-u.ac.jp/~m-mat/MT/ARTICLES/mt.pdf